{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
      "Wall time: 9.06 Âµs\n",
      "The autotime extension is already loaded. To reload it, use:\n",
      "  %reload_ext autotime\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "time: 65.9 ms\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "%load_ext autotime\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "parent_dir = os.path.abspath(os.getcwd()+'/..')+'/' \n",
    "sys.path.append(parent_dir) \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "\n",
    "from utils.path import dir_HugeFiles\n",
    "from utils.preprocessing import load\n",
    "from utils.save import make_dir, save_pickle, load_pickle, auto_save_csv, print_time, auto_save_pickle\n",
    "\n",
    "from models.fmin2 import fmin2\n",
    "from models.nested_validation import *\n",
    "from models.features import fixed_makedata, salvador_wrap, pretrained_wrap, FastText, Word2Vec, glove_wrap, doc2vec_wrap\n",
    "from models.display import pickle2df\n",
    "import multiprocessing\n",
    "\n",
    "# models\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exist\n",
      "drop 46 recipes with less than 2 ingredients\n",
      "furthur drop 1026 recipes with less than 2 instructions\n",
      "time: 14.2 s\n"
     ]
    }
   ],
   "source": [
    "### load the Recipe55k and derive Recipe54k\n",
    "dic = load('../data/dic_20190819.pickle')\n",
    "\n",
    "ls = [i for i,v in dic.items() if len(v['ingredients'])>1]\n",
    "print('drop %d recipes with less than 2 ingredients' %(len(dic)-len(ls)))\n",
    "ls = [i for i in ls if len(dic[i]['directions'])>1]\n",
    "print('furthur drop %d recipes with less than 2 instructions' %(len(dic)-len(ls)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 3min 38s\n"
     ]
    }
   ],
   "source": [
    "corp = fixed_makedata(dic, ls, tag = 'GI')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 31.7 ms\n"
     ]
    }
   ],
   "source": [
    "space = {'params':{'window': [5, 15, 25, 40],\n",
    "                'alpha': [0.025, 0.5],\n",
    "                'iter': [25, 100]}\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 90.2 ms\n"
     ]
    }
   ],
   "source": [
    "def recipe_word_embedding(fn, modelname):\n",
    "    '''\n",
    "    fn: Word2Vec of gensim ... etc\n",
    "    modelname: string: word2vec ...etc\n",
    "    '''\n",
    "    max_evals = 8\n",
    "    np.random.seed(5)\n",
    "    rd = np.random.randint(30, size=1000)\n",
    "    historical = []\n",
    "    j, num, best_loss = 0, 0, 0\n",
    "    p2 = space['params']\n",
    "    while num < max_evals:\n",
    "        new_p2 = {}\n",
    "        for k, v in p2.items():\n",
    "            if type(v) == list:\n",
    "                rand_idx = int(rd[j]%len(v))\n",
    "                new_p2[k] = v[rand_idx]\n",
    "                j+=1\n",
    "            else:\n",
    "                new_p2[k] = v\n",
    "            if j == 900:\n",
    "                j = 0\n",
    "        if new_p2 not in historical:\n",
    "            new_space = space\n",
    "            new_space.update({'p2':new_p2})\n",
    "            historical.append(new_p2)\n",
    "            # use new_space and do something            \n",
    "            num+=1\n",
    "            print(num, new_p2)\n",
    "            params_default = {'size': 300, 'window': 40, 'min_count': 5,'workers': max(1, multiprocessing.cpu_count() - 10)}\n",
    "            params_default.update(new_p2)\n",
    "\n",
    "            if modelname in ['glove']:\n",
    "                model = fn(params_default)\n",
    "                model.fit(corp.corpus_list)\n",
    "                save_pickle('../data/%s_%.2d'%(modelname,num), model)\n",
    "                \n",
    "            if modelname in ['doc2vec']:\n",
    "                params = {'main':params_default}\n",
    "                model = fn(params)\n",
    "                model.fit(corp.corpus_list)\n",
    "                save_pickle('../data/%s_%.2d'%(modelname,num), model)\n",
    "                \n",
    "            if modelname in ['word2vec','fasttext']:\n",
    "                model = fn(corp.corpus_list, **params_default)\n",
    "                model.wv.save_word2vec_format('../data/%s_%.2d.bin'%(modelname,num), binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'window': 40, 'alpha': 0.025, 'iter': 100}\n",
      "2 {'window': 15, 'alpha': 0.025, 'iter': 25}\n",
      "3 {'window': 5, 'alpha': 0.5, 'iter': 25}\n",
      "4 {'window': 5, 'alpha': 0.5, 'iter': 100}\n",
      "5 {'window': 5, 'alpha': 0.025, 'iter': 100}\n",
      "6 {'window': 15, 'alpha': 0.5, 'iter': 25}\n",
      "7 {'window': 40, 'alpha': 0.5, 'iter': 100}\n",
      "8 {'window': 25, 'alpha': 0.5, 'iter': 100}\n",
      "time: 1h 34min 2s\n"
     ]
    }
   ],
   "source": [
    "recipe_word_embedding(Word2Vec, 'word2vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'window': 40, 'alpha': 0.025, 'iter': 100}\n",
      "2 {'window': 15, 'alpha': 0.025, 'iter': 25}\n",
      "3 {'window': 5, 'alpha': 0.5, 'iter': 25}\n",
      "4 {'window': 5, 'alpha': 0.5, 'iter': 100}\n",
      "5 {'window': 5, 'alpha': 0.025, 'iter': 100}\n",
      "6 {'window': 15, 'alpha': 0.5, 'iter': 25}\n",
      "7 {'window': 40, 'alpha': 0.5, 'iter': 100}\n",
      "8 {'window': 25, 'alpha': 0.5, 'iter': 100}\n",
      "time: 16h 52min 20s\n"
     ]
    }
   ],
   "source": [
    "recipe_word_embedding(FastText, 'fasttext')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'window': 40, 'alpha': 0.025, 'iter': 100}\n",
      "2 {'window': 15, 'alpha': 0.025, 'iter': 25}\n",
      "3 {'window': 5, 'alpha': 0.5, 'iter': 25}\n",
      "4 {'window': 5, 'alpha': 0.5, 'iter': 100}\n",
      "5 {'window': 5, 'alpha': 0.025, 'iter': 100}\n",
      "6 {'window': 15, 'alpha': 0.5, 'iter': 25}\n",
      "7 {'window': 40, 'alpha': 0.5, 'iter': 100}\n",
      "8 {'window': 25, 'alpha': 0.5, 'iter': 100}\n",
      "time: 31min 27s\n"
     ]
    }
   ],
   "source": [
    "recipe_word_embedding(glove_wrap, 'glove')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 {'window': 40, 'alpha': 0.025, 'iter': 100}\n",
      "2 {'window': 15, 'alpha': 0.025, 'iter': 25}\n",
      "3 {'window': 5, 'alpha': 0.5, 'iter': 25}\n",
      "4 {'window': 5, 'alpha': 0.5, 'iter': 100}\n",
      "5 {'window': 5, 'alpha': 0.025, 'iter': 100}\n",
      "6 {'window': 15, 'alpha': 0.5, 'iter': 25}\n",
      "7 {'window': 40, 'alpha': 0.5, 'iter': 100}\n",
      "8 {'window': 25, 'alpha': 0.5, 'iter': 100}\n",
      "time: 1h 42min 50s\n"
     ]
    }
   ],
   "source": [
    "recipe_word_embedding(doc2vec_wrap, 'doc2vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare the skip thoughts vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 39 s\n"
     ]
    }
   ],
   "source": [
    "def find_max_sentence_length():\n",
    "    prev_max = 0\n",
    "    for i, v in dic.items():\n",
    "        if i in ls:\n",
    "            recipe = v['name_UNK2_none'] + v['ingredients_UNK2_none'] + v['directions_UNK2_none']\n",
    "            prev_max = max(prev_max, max([len(line) for line in recipe]))\n",
    "    return prev_max\n",
    "                       \n",
    "find_max_sentence_length()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 2.09 s\n"
     ]
    }
   ],
   "source": [
    "def export(filename, max_sent, targets, overwrite = True):\n",
    "    space = ' '.join(['NA']*max_sent)\n",
    "    make_dir(filename)\n",
    "    if os.path.isfile(filename) == True and overwrite == False:\n",
    "        print('already exists'+filename)\n",
    "    else:\n",
    "        f = open(filename, 'w')\n",
    "        for i, v in dic.items():\n",
    "            recipe = []\n",
    "            for tar in targets:\n",
    "                recipe += v[tar]\n",
    "            for line in recipe:\n",
    "                f.write(' '.join(line)+'\\n')\n",
    "            f.write(space+'\\n') \n",
    "        f.close()\n",
    "        \n",
    "filename = '../data/%s_%.2d.csv' % ('skip_thoughts_corpus',71)     \n",
    "export(filename, 71, ['name_UNK2_none','ingredients_UNK2_none', 'directions_UNK2_none'], overwrite = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
