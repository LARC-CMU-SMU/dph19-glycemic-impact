{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch # version 1.0.0\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "import os\n",
    "from data_loader import DataLoader\n",
    "from model import UniSkip\n",
    "from config import *\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "def make_dir(filename):\n",
    "    dir_path = os.path.dirname(filename)\n",
    "    if not os.path.exists(dir_path):\n",
    "        os.makedirs(dir_path)\n",
    "        print('make dir')\n",
    "\n",
    "def debug(i, loss, prev, nex, prev_pred, next_pred, saveto):\n",
    "    make_dir(saveto)\n",
    "    global loss_trail\n",
    "    global last_best_loss\n",
    "    global current_time\n",
    "\n",
    "    this_loss = loss.item()\n",
    "    loss_trail.append(this_loss)\n",
    "    loss_trail = loss_trail[-20:]\n",
    "    new_current_time = datetime.utcnow()\n",
    "    time_elapsed = str(new_current_time - current_time)\n",
    "    current_time = new_current_time\n",
    "    print(\"Iteration {}: time = {} last_best_loss = {}, this_loss = {}\".format(\n",
    "              i, time_elapsed, last_best_loss, this_loss))\n",
    "\n",
    "    try:\n",
    "        trail_loss = sum(loss_trail)/len(loss_trail)\n",
    "        if last_best_loss is None or last_best_loss > trail_loss:\n",
    "            print(\"Loss improved from {} to {}\".format(last_best_loss, trail_loss))\n",
    "            save_loc = saveto + \"skip-best-loss%.3f-epoch%5d\"%(trail_loss, i)\n",
    "            print(\"saving model at {}\".format(save_loc))\n",
    "            torch.save(mod.state_dict(), save_loc)\n",
    "            \n",
    "            last_best_loss = trail_loss\n",
    "    except Exception as e:\n",
    "        print(\"Couldn't save model because {}\".format(e))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(71, 0)\n"
     ]
    }
   ],
   "source": [
    "print((MAXLEN,CUDA_DEVICE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading text file at ../data/skip_thoughts_corpus_71.csv\n",
      "Making dictionary for these words\n",
      "Using cached dictionary at ../data/skip_thoughts_corpus_71.csv.pkl\n",
      "Making reverse dictionary\n",
      "make dir\n",
      "Iteration 0: time = 0:00:00.034922 last_best_loss = None, this_loss = 19.799667358398438\n",
      "Loss improved from None to 19.799667358398438\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss19.800-epoch    0\n",
      "Iteration 100: time = 0:00:10.506876 last_best_loss = 19.799667358398438, this_loss = 17.688419342041016\n",
      "Loss improved from 19.799667358398438 to 18.744043350219727\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.744-epoch  100\n",
      "Iteration 200: time = 0:00:13.225553 last_best_loss = 18.744043350219727, this_loss = 18.485761642456055\n",
      "Loss improved from 18.744043350219727 to 18.657949447631836\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.658-epoch  200\n",
      "Iteration 300: time = 0:00:13.103637 last_best_loss = 18.657949447631836, this_loss = 18.38467025756836\n",
      "Loss improved from 18.657949447631836 to 18.589629650115967\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.590-epoch  300\n",
      "Iteration 400: time = 0:00:19.221916 last_best_loss = 18.589629650115967, this_loss = 17.31917953491211\n",
      "Loss improved from 18.589629650115967 to 18.335539627075196\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.336-epoch  400\n",
      "Iteration 500: time = 0:00:18.951866 last_best_loss = 18.335539627075196, this_loss = 17.833581924438477\n",
      "Loss improved from 18.335539627075196 to 18.251880009969074\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.252-epoch  500\n",
      "Iteration 600: time = 0:00:18.954189 last_best_loss = 18.251880009969074, this_loss = 18.53720474243164\n",
      "Iteration 700: time = 0:00:14.921222 last_best_loss = 18.251880009969074, this_loss = 18.44646453857422\n",
      "Iteration 800: time = 0:00:14.993028 last_best_loss = 18.251880009969074, this_loss = 17.892024993896484\n",
      "Iteration 900: time = 0:00:15.025965 last_best_loss = 18.251880009969074, this_loss = 17.572166442871094\n",
      "Loss improved from 18.251880009969074 to 18.19591407775879\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.196-epoch  900\n",
      "Iteration 1000: time = 0:00:18.906362 last_best_loss = 18.19591407775879, this_loss = 18.275100708007812\n",
      "Iteration 1100: time = 0:00:15.212108 last_best_loss = 18.19591407775879, this_loss = 18.196056365966797\n",
      "Iteration 1200: time = 0:00:14.994531 last_best_loss = 18.19591407775879, this_loss = 17.6751708984375\n",
      "Loss improved from 18.19591407775879 to 18.161959134615383\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.162-epoch 1200\n",
      "Iteration 1300: time = 0:00:18.190588 last_best_loss = 18.161959134615383, this_loss = 17.711101531982422\n",
      "Loss improved from 18.161959134615383 to 18.1297550201416\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.130-epoch 1300\n",
      "Iteration 1400: time = 0:00:19.500409 last_best_loss = 18.1297550201416, this_loss = 18.290729522705078\n",
      "Iteration 1500: time = 0:00:15.006685 last_best_loss = 18.1297550201416, this_loss = 17.959781646728516\n",
      "Loss improved from 18.1297550201416 to 18.1291925907135\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.129-epoch 1500\n",
      "Iteration 1600: time = 0:00:17.212071 last_best_loss = 18.1291925907135, this_loss = 17.362834930419922\n",
      "Loss improved from 18.1291925907135 to 18.08411272834329\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.084-epoch 1600\n",
      "Iteration 1700: time = 0:00:19.649500 last_best_loss = 18.08411272834329, this_loss = 17.64600372314453\n",
      "Loss improved from 18.08411272834329 to 18.05977333916558\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.060-epoch 1700\n",
      "Iteration 1800: time = 0:00:20.767750 last_best_loss = 18.05977333916558, this_loss = 17.575927734375\n",
      "Loss improved from 18.05977333916558 to 18.034307781018708\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.034-epoch 1800\n",
      "Iteration 1900: time = 0:00:19.051252 last_best_loss = 18.034307781018708, this_loss = 17.750415802001953\n",
      "Loss improved from 18.034307781018708 to 18.02011318206787\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss18.020-epoch 1900\n",
      "Iteration 2000: time = 0:00:20.666933 last_best_loss = 18.02011318206787, this_loss = 17.15377426147461\n",
      "Loss improved from 18.02011318206787 to 17.88781852722168\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.888-epoch 2000\n",
      "Iteration 2100: time = 0:00:19.696524 last_best_loss = 17.88781852722168, this_loss = 18.54752540588379\n",
      "Iteration 2200: time = 0:00:15.076354 last_best_loss = 17.88781852722168, this_loss = 18.027667999267578\n",
      "Iteration 2300: time = 0:00:14.933467 last_best_loss = 17.88781852722168, this_loss = 17.279678344726562\n",
      "Loss improved from 17.88781852722168 to 17.852619552612303\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.853-epoch 2300\n",
      "Iteration 2400: time = 0:00:20.089621 last_best_loss = 17.852619552612303, this_loss = 17.88166046142578\n",
      "Iteration 2500: time = 0:00:15.072370 last_best_loss = 17.852619552612303, this_loss = 17.970016479492188\n",
      "Iteration 2600: time = 0:00:14.990752 last_best_loss = 17.852619552612303, this_loss = 18.09659194946289\n",
      "Iteration 2700: time = 0:00:14.638104 last_best_loss = 17.852619552612303, this_loss = 17.871074676513672\n",
      "Loss improved from 17.852619552612303 to 17.836765193939208\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.837-epoch 2700\n",
      "Iteration 2800: time = 0:00:19.511864 last_best_loss = 17.836765193939208, this_loss = 17.384082794189453\n",
      "Loss improved from 17.836765193939208 to 17.81136808395386\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.811-epoch 2800\n",
      "Iteration 2900: time = 0:00:19.464937 last_best_loss = 17.81136808395386, this_loss = 17.473857879638672\n",
      "Loss improved from 17.81136808395386 to 17.806452655792235\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.806-epoch 2900\n",
      "Iteration 3000: time = 0:00:19.800612 last_best_loss = 17.806452655792235, this_loss = 18.01526641845703\n",
      "Loss improved from 17.806452655792235 to 17.7934609413147\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.793-epoch 3000\n",
      "Iteration 3100: time = 0:00:19.115323 last_best_loss = 17.7934609413147, this_loss = 17.423477172851562\n",
      "Loss improved from 17.7934609413147 to 17.754831981658935\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.755-epoch 3100\n",
      "Iteration 3200: time = 0:00:19.316310 last_best_loss = 17.754831981658935, this_loss = 17.659326553344727\n",
      "Loss improved from 17.754831981658935 to 17.754039764404297\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.754-epoch 3200\n",
      "Iteration 3300: time = 0:00:20.058624 last_best_loss = 17.754039764404297, this_loss = 16.728816986083984\n",
      "Loss improved from 17.754039764404297 to 17.704925537109375\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.705-epoch 3300\n",
      "Iteration 3400: time = 0:00:19.538373 last_best_loss = 17.704925537109375, this_loss = 17.773550033569336\n",
      "Loss improved from 17.704925537109375 to 17.679066562652586\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.679-epoch 3400\n",
      "Iteration 3500: time = 0:00:19.613312 last_best_loss = 17.679066562652586, this_loss = 17.552217483520508\n",
      "Loss improved from 17.679066562652586 to 17.658688354492188\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.659-epoch 3500\n",
      "Iteration 3600: time = 0:00:19.616437 last_best_loss = 17.658688354492188, this_loss = 17.617143630981445\n",
      "Iteration 3700: time = 0:00:14.928556 last_best_loss = 17.658688354492188, this_loss = 17.530370712280273\n",
      "Iteration 3800: time = 0:00:14.759486 last_best_loss = 17.658688354492188, this_loss = 17.839630126953125\n",
      "Iteration 3900: time = 0:00:12.571434 last_best_loss = 17.658688354492188, this_loss = 18.118345260620117\n",
      "Iteration 4000: time = 0:00:08.044621 last_best_loss = 17.658688354492188, this_loss = 17.802661895751953\n",
      "Iteration 4100: time = 0:00:08.229671 last_best_loss = 17.658688354492188, this_loss = 17.165119171142578\n",
      "Iteration 4200: time = 0:00:07.979203 last_best_loss = 17.658688354492188, this_loss = 17.540855407714844\n",
      "Loss improved from 17.658688354492188 to 17.636187171936037\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.636-epoch 4200\n",
      "Iteration 4300: time = 0:00:12.471902 last_best_loss = 17.636187171936037, this_loss = 17.87417984008789\n",
      "Iteration 4400: time = 0:00:07.708155 last_best_loss = 17.636187171936037, this_loss = 17.35173797607422\n",
      "Iteration 4500: time = 0:00:07.713107 last_best_loss = 17.636187171936037, this_loss = 17.64435577392578\n",
      "Loss improved from 17.636187171936037 to 17.6231330871582\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.623-epoch 4500\n",
      "Iteration 4600: time = 0:00:12.681662 last_best_loss = 17.6231330871582, this_loss = 17.480976104736328\n",
      "Loss improved from 17.6231330871582 to 17.592352294921874\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.592-epoch 4600\n",
      "Iteration 4700: time = 0:00:12.930693 last_best_loss = 17.592352294921874, this_loss = 17.562801361083984\n",
      "Loss improved from 17.592352294921874 to 17.57693862915039\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.577-epoch 4700\n",
      "Iteration 4800: time = 0:00:12.243969 last_best_loss = 17.57693862915039, this_loss = 17.301143646240234\n",
      "Loss improved from 17.57693862915039 to 17.57279167175293\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.573-epoch 4800\n",
      "Iteration 4900: time = 0:00:12.034591 last_best_loss = 17.57279167175293, this_loss = 17.65179443359375\n",
      "Iteration 5000: time = 0:00:07.718188 last_best_loss = 17.57279167175293, this_loss = 17.813976287841797\n",
      "Loss improved from 17.57279167175293 to 17.57162399291992\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.572-epoch 5000\n",
      "Iteration 5100: time = 0:00:12.644427 last_best_loss = 17.57162399291992, this_loss = 17.785886764526367\n",
      "Iteration 5200: time = 0:00:07.700085 last_best_loss = 17.57162399291992, this_loss = 17.136943817138672\n",
      "Loss improved from 17.57162399291992 to 17.56362533569336\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.564-epoch 5200\n",
      "Iteration 5300: time = 0:00:12.765536 last_best_loss = 17.56362533569336, this_loss = 17.282699584960938\n",
      "Iteration 5400: time = 0:00:07.750611 last_best_loss = 17.56362533569336, this_loss = 17.52353858947754\n",
      "Iteration 5500: time = 0:00:07.788364 last_best_loss = 17.56362533569336, this_loss = 16.98035430908203\n",
      "Loss improved from 17.56362533569336 to 17.550225734710693\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.550-epoch 5500\n",
      "Iteration 5600: time = 0:00:10.126858 last_best_loss = 17.550225734710693, this_loss = 17.240135192871094\n",
      "Loss improved from 17.550225734710693 to 17.531375312805174\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.531-epoch 5600\n",
      "Iteration 5700: time = 0:00:10.404876 last_best_loss = 17.531375312805174, this_loss = 16.951316833496094\n",
      "Loss improved from 17.531375312805174 to 17.502422618865968\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.502-epoch 5700\n",
      "Iteration 5800: time = 0:00:10.617868 last_best_loss = 17.502422618865968, this_loss = 17.888845443725586\n",
      "Iteration 5900: time = 0:00:07.739092 last_best_loss = 17.502422618865968, this_loss = 17.04051399230957\n",
      "Loss improved from 17.502422618865968 to 17.450991821289062\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.451-epoch 5900\n",
      "Iteration 6000: time = 0:00:10.866364 last_best_loss = 17.450991821289062, this_loss = 17.24004364013672\n",
      "Loss improved from 17.450991821289062 to 17.4228609085083\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.423-epoch 6000\n",
      "Iteration 6100: time = 0:00:12.449579 last_best_loss = 17.4228609085083, this_loss = 17.888267517089844\n",
      "Iteration 6200: time = 0:00:08.172204 last_best_loss = 17.4228609085083, this_loss = 17.012845993041992\n",
      "Iteration 6300: time = 0:00:07.778241 last_best_loss = 17.4228609085083, this_loss = 17.46385383605957\n",
      "Loss improved from 17.4228609085083 to 17.412101554870606\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.412-epoch 6300\n",
      "Iteration 6400: time = 0:00:12.318105 last_best_loss = 17.412101554870606, this_loss = 17.143516540527344\n",
      "Loss improved from 17.412101554870606 to 17.40169048309326\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.402-epoch 6400\n",
      "Iteration 6500: time = 0:00:12.653286 last_best_loss = 17.40169048309326, this_loss = 17.05230712890625\n",
      "Loss improved from 17.40169048309326 to 17.372088050842287\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.372-epoch 6500\n",
      "Iteration 6600: time = 0:00:11.001378 last_best_loss = 17.372088050842287, this_loss = 17.8067626953125\n",
      "Iteration 6700: time = 0:00:07.699819 last_best_loss = 17.372088050842287, this_loss = 17.354774475097656\n",
      "Iteration 6800: time = 0:00:07.728568 last_best_loss = 17.372088050842287, this_loss = 18.18419647216797\n",
      "Iteration 6900: time = 0:00:07.654418 last_best_loss = 17.372088050842287, this_loss = 17.731266021728516\n",
      "Iteration 7000: time = 0:00:07.718515 last_best_loss = 17.372088050842287, this_loss = 18.03917694091797\n",
      "Iteration 7100: time = 0:00:07.717381 last_best_loss = 17.372088050842287, this_loss = 17.34398078918457\n",
      "Iteration 7200: time = 0:00:07.640076 last_best_loss = 17.372088050842287, this_loss = 17.256702423095703\n",
      "Iteration 7300: time = 0:00:07.717998 last_best_loss = 17.372088050842287, this_loss = 17.50203514099121\n",
      "Iteration 7400: time = 0:00:07.712389 last_best_loss = 17.372088050842287, this_loss = 17.181289672851562\n",
      "Iteration 7500: time = 0:00:07.727200 last_best_loss = 17.372088050842287, this_loss = 17.1619873046875\n",
      "Iteration 7600: time = 0:00:07.788903 last_best_loss = 17.372088050842287, this_loss = 17.721120834350586\n",
      "Iteration 7700: time = 0:00:07.768852 last_best_loss = 17.372088050842287, this_loss = 17.713956832885742\n",
      "Iteration 7800: time = 0:00:07.746221 last_best_loss = 17.372088050842287, this_loss = 17.45431900024414\n",
      "Iteration 7900: time = 0:00:07.729080 last_best_loss = 17.372088050842287, this_loss = 18.005409240722656\n",
      "Iteration 8000: time = 0:00:07.732559 last_best_loss = 17.372088050842287, this_loss = 17.759750366210938\n",
      "Iteration 8100: time = 0:00:07.728723 last_best_loss = 17.372088050842287, this_loss = 17.40252113342285\n",
      "Iteration 8200: time = 0:00:07.769242 last_best_loss = 17.372088050842287, this_loss = 17.481708526611328\n",
      "Iteration 8300: time = 0:00:07.799408 last_best_loss = 17.372088050842287, this_loss = 17.49126625061035\n",
      "Iteration 8400: time = 0:00:07.726962 last_best_loss = 17.372088050842287, this_loss = 17.925125122070312\n",
      "Iteration 8500: time = 0:00:07.716182 last_best_loss = 17.372088050842287, this_loss = 17.115800857543945\n",
      "Iteration 8600: time = 0:00:07.701957 last_best_loss = 17.372088050842287, this_loss = 17.426921844482422\n",
      "Iteration 8700: time = 0:00:07.763314 last_best_loss = 17.372088050842287, this_loss = 17.498271942138672\n",
      "Iteration 8800: time = 0:00:07.732744 last_best_loss = 17.372088050842287, this_loss = 17.03660774230957\n",
      "Iteration 8900: time = 0:00:07.693812 last_best_loss = 17.372088050842287, this_loss = 17.59060287475586\n",
      "Iteration 9000: time = 0:00:07.720008 last_best_loss = 17.372088050842287, this_loss = 17.33216094970703\n",
      "Iteration 9100: time = 0:00:07.704934 last_best_loss = 17.372088050842287, this_loss = 17.993873596191406\n",
      "Iteration 9200: time = 0:00:07.700380 last_best_loss = 17.372088050842287, this_loss = 17.363449096679688\n",
      "Iteration 9300: time = 0:00:07.721802 last_best_loss = 17.372088050842287, this_loss = 17.55948257446289\n",
      "Iteration 9400: time = 0:00:07.796082 last_best_loss = 17.372088050842287, this_loss = 16.833389282226562\n",
      "Iteration 9500: time = 0:00:07.697246 last_best_loss = 17.372088050842287, this_loss = 17.952415466308594\n",
      "Iteration 9600: time = 0:00:07.729016 last_best_loss = 17.372088050842287, this_loss = 17.084367752075195\n",
      "Iteration 9700: time = 0:00:07.718161 last_best_loss = 17.372088050842287, this_loss = 17.373699188232422\n",
      "Iteration 9800: time = 0:00:07.728767 last_best_loss = 17.372088050842287, this_loss = 17.237329483032227\n",
      "Iteration 9900: time = 0:00:07.756271 last_best_loss = 17.372088050842287, this_loss = 17.26278305053711\n",
      "Iteration 10000: time = 0:00:07.730190 last_best_loss = 17.372088050842287, this_loss = 17.03946876525879\n",
      "Iteration 10100: time = 0:00:07.761151 last_best_loss = 17.372088050842287, this_loss = 17.784393310546875\n",
      "Iteration 10200: time = 0:00:07.773970 last_best_loss = 17.372088050842287, this_loss = 17.528236389160156\n",
      "Iteration 10300: time = 0:00:07.676465 last_best_loss = 17.372088050842287, this_loss = 17.345073699951172\n",
      "Iteration 10400: time = 0:00:07.900201 last_best_loss = 17.372088050842287, this_loss = 17.222354888916016\n",
      "Iteration 10500: time = 0:00:07.708570 last_best_loss = 17.372088050842287, this_loss = 17.299243927001953\n",
      "Iteration 10600: time = 0:00:07.736412 last_best_loss = 17.372088050842287, this_loss = 16.705184936523438\n",
      "Loss improved from 17.372088050842287 to 17.35211944580078\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.352-epoch10600\n",
      "Iteration 10700: time = 0:00:13.028239 last_best_loss = 17.35211944580078, this_loss = 17.4234619140625\n",
      "Loss improved from 17.35211944580078 to 17.348378944396973\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.348-epoch10700\n",
      "Iteration 10800: time = 0:00:12.101974 last_best_loss = 17.348378944396973, this_loss = 17.55170440673828\n",
      "Iteration 10900: time = 0:00:07.659127 last_best_loss = 17.348378944396973, this_loss = 17.27256202697754\n",
      "Iteration 11000: time = 0:00:07.961867 last_best_loss = 17.348378944396973, this_loss = 17.013622283935547\n",
      "Loss improved from 17.348378944396973 to 17.34230480194092\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.342-epoch11000\n",
      "Iteration 11100: time = 0:00:12.037587 last_best_loss = 17.34230480194092, this_loss = 17.22971534729004\n",
      "Loss improved from 17.34230480194092 to 17.30409688949585\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.304-epoch11100\n",
      "Iteration 11200: time = 0:00:12.769359 last_best_loss = 17.30409688949585, this_loss = 17.7557430267334\n",
      "Iteration 11300: time = 0:00:07.715069 last_best_loss = 17.30409688949585, this_loss = 17.146385192871094\n",
      "Loss improved from 17.30409688949585 to 17.303056716918945\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.303-epoch11300\n",
      "Iteration 11400: time = 0:00:12.719172 last_best_loss = 17.303056716918945, this_loss = 16.676517486572266\n",
      "Loss improved from 17.303056716918945 to 17.29521312713623\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.295-epoch11400\n",
      "Iteration 11500: time = 0:00:10.651397 last_best_loss = 17.29521312713623, this_loss = 17.349069595336914\n",
      "Loss improved from 17.29521312713623 to 17.265045833587646\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.265-epoch11500\n",
      "Iteration 11600: time = 0:00:12.010441 last_best_loss = 17.265045833587646, this_loss = 17.026626586914062\n",
      "Loss improved from 17.265045833587646 to 17.26215877532959\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.262-epoch11600\n",
      "Iteration 11700: time = 0:00:12.268364 last_best_loss = 17.26215877532959, this_loss = 17.099262237548828\n",
      "Loss improved from 17.26215877532959 to 17.24843692779541\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.248-epoch11700\n",
      "Iteration 11800: time = 0:00:13.378954 last_best_loss = 17.24843692779541, this_loss = 17.420215606689453\n",
      "Iteration 11900: time = 0:00:07.742006 last_best_loss = 17.24843692779541, this_loss = 17.104820251464844\n",
      "Iteration 12000: time = 0:00:07.736619 last_best_loss = 17.24843692779541, this_loss = 17.465381622314453\n",
      "Iteration 12100: time = 0:00:08.120579 last_best_loss = 17.24843692779541, this_loss = 17.747297286987305\n",
      "Iteration 12200: time = 0:00:07.769113 last_best_loss = 17.24843692779541, this_loss = 16.822683334350586\n",
      "Loss improved from 17.24843692779541 to 17.233846282958986\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.234-epoch12200\n",
      "Iteration 12300: time = 0:00:12.265078 last_best_loss = 17.233846282958986, this_loss = 16.801513671875\n",
      "Loss improved from 17.233846282958986 to 17.206668281555174\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.207-epoch12300\n",
      "Iteration 12400: time = 0:00:12.782005 last_best_loss = 17.206668281555174, this_loss = 17.886594772338867\n",
      "Iteration 12500: time = 0:00:07.694999 last_best_loss = 17.206668281555174, this_loss = 17.56741714477539\n",
      "Iteration 12600: time = 0:00:07.758424 last_best_loss = 17.206668281555174, this_loss = 17.52761459350586\n",
      "Iteration 12700: time = 0:00:07.706307 last_best_loss = 17.206668281555174, this_loss = 17.563709259033203\n",
      "Iteration 12800: time = 0:00:07.746087 last_best_loss = 17.206668281555174, this_loss = 17.863679885864258\n",
      "Iteration 12900: time = 0:00:07.729395 last_best_loss = 17.206668281555174, this_loss = 17.6296443939209\n",
      "Iteration 13000: time = 0:00:07.777403 last_best_loss = 17.206668281555174, this_loss = 18.00387191772461\n",
      "Iteration 13100: time = 0:00:07.737336 last_best_loss = 17.206668281555174, this_loss = 17.683879852294922\n",
      "Iteration 13200: time = 0:00:07.716152 last_best_loss = 17.206668281555174, this_loss = 17.52686882019043\n",
      "Iteration 13300: time = 0:00:07.707933 last_best_loss = 17.206668281555174, this_loss = 17.599552154541016\n",
      "Iteration 13400: time = 0:00:07.718097 last_best_loss = 17.206668281555174, this_loss = 16.576400756835938\n",
      "Iteration 13500: time = 0:00:07.744015 last_best_loss = 17.206668281555174, this_loss = 17.72272491455078\n",
      "Iteration 13600: time = 0:00:07.769680 last_best_loss = 17.206668281555174, this_loss = 16.979793548583984\n",
      "Iteration 13700: time = 0:00:07.898922 last_best_loss = 17.206668281555174, this_loss = 16.749427795410156\n",
      "Iteration 13800: time = 0:00:07.726105 last_best_loss = 17.206668281555174, this_loss = 16.96831512451172\n",
      "Iteration 13900: time = 0:00:07.728372 last_best_loss = 17.206668281555174, this_loss = 17.635177612304688\n",
      "Iteration 14000: time = 0:00:07.717282 last_best_loss = 17.206668281555174, this_loss = 17.269210815429688\n",
      "Iteration 14100: time = 0:00:07.744177 last_best_loss = 17.206668281555174, this_loss = 17.369638442993164\n",
      "Iteration 14200: time = 0:00:07.754444 last_best_loss = 17.206668281555174, this_loss = 16.403400421142578\n",
      "Iteration 14300: time = 0:00:07.824878 last_best_loss = 17.206668281555174, this_loss = 17.662609100341797\n",
      "Iteration 14400: time = 0:00:07.776962 last_best_loss = 17.206668281555174, this_loss = 17.63137435913086\n",
      "Iteration 14500: time = 0:00:07.825595 last_best_loss = 17.206668281555174, this_loss = 17.166584014892578\n",
      "Iteration 14600: time = 0:00:07.925248 last_best_loss = 17.206668281555174, this_loss = 16.982322692871094\n",
      "Iteration 14700: time = 0:00:07.678961 last_best_loss = 17.206668281555174, this_loss = 17.587753295898438\n",
      "Iteration 14800: time = 0:00:07.704348 last_best_loss = 17.206668281555174, this_loss = 17.434528350830078\n",
      "Iteration 14900: time = 0:00:07.731861 last_best_loss = 17.206668281555174, this_loss = 17.887733459472656\n",
      "Iteration 15000: time = 0:00:07.723124 last_best_loss = 17.206668281555174, this_loss = 17.623659133911133\n",
      "Iteration 15100: time = 0:00:07.925492 last_best_loss = 17.206668281555174, this_loss = 17.882150650024414\n",
      "Iteration 15200: time = 0:00:07.766041 last_best_loss = 17.206668281555174, this_loss = 17.026893615722656\n",
      "Iteration 15300: time = 0:00:07.803088 last_best_loss = 17.206668281555174, this_loss = 18.011287689208984\n",
      "Iteration 15400: time = 0:00:07.723409 last_best_loss = 17.206668281555174, this_loss = 16.709564208984375\n",
      "Iteration 15500: time = 0:00:16.584321 last_best_loss = 17.206668281555174, this_loss = 17.758853912353516\n",
      "Iteration 15600: time = 0:00:07.722165 last_best_loss = 17.206668281555174, this_loss = 17.709548950195312\n",
      "Iteration 15700: time = 0:00:07.670308 last_best_loss = 17.206668281555174, this_loss = 17.367610931396484\n",
      "Iteration 15800: time = 0:00:07.774361 last_best_loss = 17.206668281555174, this_loss = 17.038471221923828\n",
      "Iteration 15900: time = 0:00:07.748747 last_best_loss = 17.206668281555174, this_loss = 17.284053802490234\n",
      "Iteration 16000: time = 0:00:07.760083 last_best_loss = 17.206668281555174, this_loss = 16.871347427368164\n",
      "Iteration 16100: time = 0:00:07.788347 last_best_loss = 17.206668281555174, this_loss = 17.520875930786133\n",
      "Iteration 16200: time = 0:00:07.846994 last_best_loss = 17.206668281555174, this_loss = 17.710739135742188\n",
      "Iteration 16300: time = 0:00:07.715522 last_best_loss = 17.206668281555174, this_loss = 17.596202850341797\n",
      "Iteration 16400: time = 0:00:07.793647 last_best_loss = 17.206668281555174, this_loss = 17.874916076660156\n",
      "Iteration 16500: time = 0:00:07.767147 last_best_loss = 17.206668281555174, this_loss = 17.95636749267578\n",
      "Iteration 16600: time = 0:00:07.728374 last_best_loss = 17.206668281555174, this_loss = 17.966228485107422\n",
      "Iteration 16700: time = 0:00:07.757480 last_best_loss = 17.206668281555174, this_loss = 16.513059616088867\n",
      "Iteration 16800: time = 0:00:07.943976 last_best_loss = 17.206668281555174, this_loss = 16.990970611572266\n",
      "Iteration 16900: time = 0:00:07.707154 last_best_loss = 17.206668281555174, this_loss = 17.303014755249023\n",
      "Iteration 17000: time = 0:00:07.654644 last_best_loss = 17.206668281555174, this_loss = 17.846702575683594\n",
      "Iteration 17100: time = 0:00:07.695761 last_best_loss = 17.206668281555174, this_loss = 17.42363739013672\n",
      "Iteration 17200: time = 0:00:07.679475 last_best_loss = 17.206668281555174, this_loss = 17.222591400146484\n",
      "Iteration 17300: time = 0:00:07.784484 last_best_loss = 17.206668281555174, this_loss = 18.131710052490234\n",
      "Iteration 17400: time = 0:00:07.744416 last_best_loss = 17.206668281555174, this_loss = 17.625629425048828\n",
      "Iteration 17500: time = 0:00:07.792081 last_best_loss = 17.206668281555174, this_loss = 16.480876922607422\n",
      "Iteration 17600: time = 0:00:07.734743 last_best_loss = 17.206668281555174, this_loss = 17.109560012817383\n",
      "Iteration 17700: time = 0:00:07.676772 last_best_loss = 17.206668281555174, this_loss = 17.64862823486328\n",
      "Iteration 17800: time = 0:00:07.749093 last_best_loss = 17.206668281555174, this_loss = 17.826488494873047\n",
      "Iteration 17900: time = 0:00:07.757995 last_best_loss = 17.206668281555174, this_loss = 16.963472366333008\n",
      "Iteration 18000: time = 0:00:07.729944 last_best_loss = 17.206668281555174, this_loss = 17.86138916015625\n",
      "Iteration 18100: time = 0:00:07.745431 last_best_loss = 17.206668281555174, this_loss = 18.1008358001709\n",
      "Iteration 18200: time = 0:00:07.700858 last_best_loss = 17.206668281555174, this_loss = 17.074623107910156\n",
      "Iteration 18300: time = 0:00:07.732356 last_best_loss = 17.206668281555174, this_loss = 17.470670700073242\n",
      "Iteration 18400: time = 0:00:07.672940 last_best_loss = 17.206668281555174, this_loss = 17.383405685424805\n",
      "Iteration 18500: time = 0:00:07.774047 last_best_loss = 17.206668281555174, this_loss = 16.775802612304688\n",
      "Iteration 18600: time = 0:00:07.726949 last_best_loss = 17.206668281555174, this_loss = 16.931869506835938\n",
      "Iteration 18700: time = 0:00:07.767701 last_best_loss = 17.206668281555174, this_loss = 17.144962310791016\n",
      "Iteration 18800: time = 0:00:07.704744 last_best_loss = 17.206668281555174, this_loss = 17.489665985107422\n",
      "Iteration 18900: time = 0:00:07.750743 last_best_loss = 17.206668281555174, this_loss = 17.223918914794922\n",
      "Iteration 19000: time = 0:00:07.908743 last_best_loss = 17.206668281555174, this_loss = 17.239990234375\n",
      "Iteration 19100: time = 0:00:08.015622 last_best_loss = 17.206668281555174, this_loss = 17.40941619873047\n",
      "Iteration 19200: time = 0:00:07.726353 last_best_loss = 17.206668281555174, this_loss = 16.696216583251953\n",
      "Iteration 19300: time = 0:00:07.792595 last_best_loss = 17.206668281555174, this_loss = 18.01217269897461\n",
      "Iteration 19400: time = 0:00:07.856626 last_best_loss = 17.206668281555174, this_loss = 17.53244972229004\n",
      "Iteration 19500: time = 0:00:07.715630 last_best_loss = 17.206668281555174, this_loss = 17.625064849853516\n",
      "Iteration 19600: time = 0:00:07.705368 last_best_loss = 17.206668281555174, this_loss = 17.416481018066406\n",
      "Iteration 19700: time = 0:00:07.700234 last_best_loss = 17.206668281555174, this_loss = 17.611175537109375\n",
      "Iteration 19800: time = 0:00:07.900942 last_best_loss = 17.206668281555174, this_loss = 17.109481811523438\n",
      "Iteration 19900: time = 0:00:07.751080 last_best_loss = 17.206668281555174, this_loss = 17.816322326660156\n",
      "Iteration 20000: time = 0:00:07.654284 last_best_loss = 17.206668281555174, this_loss = 16.948196411132812\n",
      "Iteration 20100: time = 0:00:07.675642 last_best_loss = 17.206668281555174, this_loss = 17.501789093017578\n",
      "Iteration 20200: time = 0:00:07.659727 last_best_loss = 17.206668281555174, this_loss = 17.632946014404297\n",
      "Iteration 20300: time = 0:00:07.683355 last_best_loss = 17.206668281555174, this_loss = 17.522674560546875\n",
      "Iteration 20400: time = 0:00:07.639230 last_best_loss = 17.206668281555174, this_loss = 17.050289154052734\n",
      "Iteration 20500: time = 0:00:07.691288 last_best_loss = 17.206668281555174, this_loss = 17.246057510375977\n",
      "Iteration 20600: time = 0:00:07.674075 last_best_loss = 17.206668281555174, this_loss = 17.207059860229492\n",
      "Iteration 20700: time = 0:00:07.743997 last_best_loss = 17.206668281555174, this_loss = 16.854488372802734\n",
      "Iteration 20800: time = 0:00:07.799591 last_best_loss = 17.206668281555174, this_loss = 17.25586700439453\n",
      "Iteration 20900: time = 0:00:07.967987 last_best_loss = 17.206668281555174, this_loss = 17.373828887939453\n",
      "Iteration 21000: time = 0:00:07.668625 last_best_loss = 17.206668281555174, this_loss = 17.563434600830078\n",
      "Iteration 21100: time = 0:00:07.723696 last_best_loss = 17.206668281555174, this_loss = 17.480915069580078\n",
      "Iteration 21200: time = 0:00:07.707124 last_best_loss = 17.206668281555174, this_loss = 17.884912490844727\n",
      "Iteration 21300: time = 0:00:07.736181 last_best_loss = 17.206668281555174, this_loss = 17.33203125\n",
      "Iteration 21400: time = 0:00:07.705099 last_best_loss = 17.206668281555174, this_loss = 17.364221572875977\n",
      "Iteration 21500: time = 0:00:07.672334 last_best_loss = 17.206668281555174, this_loss = 17.495845794677734\n",
      "Iteration 21600: time = 0:00:07.698971 last_best_loss = 17.206668281555174, this_loss = 16.994375228881836\n",
      "Iteration 21700: time = 0:00:07.714537 last_best_loss = 17.206668281555174, this_loss = 17.600378036499023\n",
      "Iteration 21800: time = 0:00:07.687227 last_best_loss = 17.206668281555174, this_loss = 17.87970733642578\n",
      "Iteration 21900: time = 0:00:07.719542 last_best_loss = 17.206668281555174, this_loss = 16.801410675048828\n",
      "Iteration 22000: time = 0:00:07.661936 last_best_loss = 17.206668281555174, this_loss = 17.19762420654297\n",
      "Iteration 22100: time = 0:00:07.691474 last_best_loss = 17.206668281555174, this_loss = 16.593944549560547\n",
      "Iteration 22200: time = 0:00:07.727847 last_best_loss = 17.206668281555174, this_loss = 17.112964630126953\n",
      "Iteration 22300: time = 0:00:07.717469 last_best_loss = 17.206668281555174, this_loss = 16.769580841064453\n",
      "Iteration 22400: time = 0:00:07.688018 last_best_loss = 17.206668281555174, this_loss = 16.838132858276367\n",
      "Iteration 22500: time = 0:00:07.698822 last_best_loss = 17.206668281555174, this_loss = 17.297319412231445\n",
      "Iteration 22600: time = 0:00:07.664351 last_best_loss = 17.206668281555174, this_loss = 17.378578186035156\n",
      "Iteration 22700: time = 0:00:07.634647 last_best_loss = 17.206668281555174, this_loss = 16.888179779052734\n",
      "Iteration 22800: time = 0:00:07.675135 last_best_loss = 17.206668281555174, this_loss = 17.060272216796875\n",
      "Iteration 22900: time = 0:00:07.704362 last_best_loss = 17.206668281555174, this_loss = 17.967979431152344\n",
      "Iteration 23000: time = 0:00:07.701248 last_best_loss = 17.206668281555174, this_loss = 17.059654235839844\n",
      "Iteration 23100: time = 0:00:08.009668 last_best_loss = 17.206668281555174, this_loss = 17.482749938964844\n",
      "Iteration 23200: time = 0:00:07.827881 last_best_loss = 17.206668281555174, this_loss = 17.93465805053711\n",
      "Iteration 23300: time = 0:00:07.720810 last_best_loss = 17.206668281555174, this_loss = 17.37647247314453\n",
      "Iteration 23400: time = 0:00:07.702289 last_best_loss = 17.206668281555174, this_loss = 18.15890884399414\n",
      "Iteration 23500: time = 0:00:08.002280 last_best_loss = 17.206668281555174, this_loss = 17.343290328979492\n",
      "Iteration 23600: time = 0:00:07.834399 last_best_loss = 17.206668281555174, this_loss = 17.236038208007812\n",
      "Iteration 23700: time = 0:00:07.716780 last_best_loss = 17.206668281555174, this_loss = 16.90087890625\n",
      "Iteration 23800: time = 0:00:07.695765 last_best_loss = 17.206668281555174, this_loss = 17.330135345458984\n",
      "Iteration 23900: time = 0:00:07.741023 last_best_loss = 17.206668281555174, this_loss = 16.647708892822266\n",
      "Iteration 24000: time = 0:00:07.789009 last_best_loss = 17.206668281555174, this_loss = 17.222366333007812\n",
      "Iteration 24100: time = 0:00:07.722188 last_best_loss = 17.206668281555174, this_loss = 18.037609100341797\n",
      "Iteration 24200: time = 0:00:07.692250 last_best_loss = 17.206668281555174, this_loss = 17.641094207763672\n",
      "Iteration 24300: time = 0:00:07.855807 last_best_loss = 17.206668281555174, this_loss = 17.128154754638672\n",
      "Iteration 24400: time = 0:00:07.722544 last_best_loss = 17.206668281555174, this_loss = 16.569725036621094\n",
      "Iteration 24500: time = 0:00:07.758260 last_best_loss = 17.206668281555174, this_loss = 16.973663330078125\n",
      "Iteration 24600: time = 0:00:07.950745 last_best_loss = 17.206668281555174, this_loss = 16.94062042236328\n",
      "Iteration 24700: time = 0:00:07.713246 last_best_loss = 17.206668281555174, this_loss = 17.309873580932617\n",
      "Iteration 24800: time = 0:00:07.717721 last_best_loss = 17.206668281555174, this_loss = 17.374732971191406\n",
      "Iteration 24900: time = 0:00:08.103545 last_best_loss = 17.206668281555174, this_loss = 16.412160873413086\n",
      "Iteration 25000: time = 0:00:07.691212 last_best_loss = 17.206668281555174, this_loss = 17.09856414794922\n",
      "Iteration 25100: time = 0:00:07.691853 last_best_loss = 17.206668281555174, this_loss = 16.846439361572266\n",
      "Iteration 25200: time = 0:00:07.679199 last_best_loss = 17.206668281555174, this_loss = 17.598865509033203\n",
      "Iteration 25300: time = 0:00:07.693936 last_best_loss = 17.206668281555174, this_loss = 16.34054183959961\n",
      "Loss improved from 17.206668281555174 to 17.155568599700928\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.156-epoch25300\n",
      "Iteration 25400: time = 0:00:12.821056 last_best_loss = 17.155568599700928, this_loss = 17.736364364624023\n",
      "Loss improved from 17.155568599700928 to 17.134441375732422\n",
      "saving model at ../data/skip_thoughts_corpus_71/skip-best-loss17.134-epoch25400\n",
      "Iteration 25500: time = 0:00:11.912532 last_best_loss = 17.134441375732422, this_loss = 17.56882095336914\n",
      "Iteration 25600: time = 0:00:07.592044 last_best_loss = 17.134441375732422, this_loss = 17.562118530273438\n",
      "Iteration 25700: time = 0:00:07.687707 last_best_loss = 17.134441375732422, this_loss = 17.229103088378906\n",
      "Iteration 25800: time = 0:00:07.597877 last_best_loss = 17.134441375732422, this_loss = 17.208829879760742\n",
      "Iteration 25900: time = 0:00:07.673737 last_best_loss = 17.134441375732422, this_loss = 16.792490005493164\n",
      "Iteration 26000: time = 0:00:08.003813 last_best_loss = 17.134441375732422, this_loss = 17.621044158935547\n",
      "Iteration 26100: time = 0:00:07.666851 last_best_loss = 17.134441375732422, this_loss = 17.180143356323242\n",
      "Iteration 26200: time = 0:00:07.713457 last_best_loss = 17.134441375732422, this_loss = 17.260272979736328\n",
      "Iteration 26300: time = 0:00:07.681282 last_best_loss = 17.134441375732422, this_loss = 17.229888916015625\n",
      "Iteration 26400: time = 0:00:07.712480 last_best_loss = 17.134441375732422, this_loss = 17.70326805114746\n",
      "Iteration 26500: time = 0:00:07.726529 last_best_loss = 17.134441375732422, this_loss = 16.959278106689453\n",
      "Iteration 26600: time = 0:00:07.662027 last_best_loss = 17.134441375732422, this_loss = 17.13546371459961\n",
      "Iteration 26700: time = 0:00:07.638646 last_best_loss = 17.134441375732422, this_loss = 17.710525512695312\n",
      "Iteration 26800: time = 0:00:07.638783 last_best_loss = 17.134441375732422, this_loss = 17.013181686401367\n",
      "Iteration 26900: time = 0:00:07.910178 last_best_loss = 17.134441375732422, this_loss = 18.53262710571289\n",
      "Iteration 27000: time = 0:00:07.728820 last_best_loss = 17.134441375732422, this_loss = 17.207799911499023\n",
      "Iteration 27100: time = 0:00:07.725644 last_best_loss = 17.134441375732422, this_loss = 17.038570404052734\n",
      "Iteration 27200: time = 0:00:07.718594 last_best_loss = 17.134441375732422, this_loss = 16.875255584716797\n",
      "Iteration 27300: time = 0:00:07.675951 last_best_loss = 17.134441375732422, this_loss = 16.648788452148438\n",
      "Iteration 27400: time = 0:00:07.710728 last_best_loss = 17.134441375732422, this_loss = 16.95458221435547\n",
      "Iteration 27500: time = 0:00:07.617460 last_best_loss = 17.134441375732422, this_loss = 16.84585952758789\n",
      "Iteration 27600: time = 0:00:07.663340 last_best_loss = 17.134441375732422, this_loss = 18.117145538330078\n",
      "Iteration 27700: time = 0:00:07.716402 last_best_loss = 17.134441375732422, this_loss = 16.89232635498047\n",
      "Iteration 27800: time = 0:00:07.730982 last_best_loss = 17.134441375732422, this_loss = 17.135387420654297\n",
      "Iteration 27900: time = 0:00:07.653300 last_best_loss = 17.134441375732422, this_loss = 17.88727569580078\n",
      "Iteration 28000: time = 0:00:07.680278 last_best_loss = 17.134441375732422, this_loss = 17.208473205566406\n",
      "Iteration 28100: time = 0:00:08.378877 last_best_loss = 17.134441375732422, this_loss = 16.831172943115234\n",
      "Iteration 28200: time = 0:00:07.917742 last_best_loss = 17.134441375732422, this_loss = 16.719703674316406\n",
      "Iteration 28300: time = 0:00:07.690268 last_best_loss = 17.134441375732422, this_loss = 17.689071655273438\n",
      "Iteration 28400: time = 0:00:07.728332 last_best_loss = 17.134441375732422, this_loss = 17.727272033691406\n",
      "Iteration 28500: time = 0:00:07.817173 last_best_loss = 17.134441375732422, this_loss = 16.434001922607422\n",
      "Iteration 28600: time = 0:00:07.665774 last_best_loss = 17.134441375732422, this_loss = 17.349952697753906\n",
      "Iteration 28700: time = 0:00:07.689585 last_best_loss = 17.134441375732422, this_loss = 16.98492431640625\n",
      "Iteration 28800: time = 0:00:07.727829 last_best_loss = 17.134441375732422, this_loss = 16.97694969177246\n",
      "Iteration 28900: time = 0:00:07.693907 last_best_loss = 17.134441375732422, this_loss = 17.34329605102539\n",
      "Iteration 29000: time = 0:00:07.693272 last_best_loss = 17.134441375732422, this_loss = 17.593894958496094\n",
      "Iteration 29100: time = 0:00:07.723326 last_best_loss = 17.134441375732422, this_loss = 16.933364868164062\n",
      "Iteration 29200: time = 0:00:07.712710 last_best_loss = 17.134441375732422, this_loss = 17.950904846191406\n",
      "Iteration 29300: time = 0:00:07.759814 last_best_loss = 17.134441375732422, this_loss = 17.440692901611328\n",
      "Iteration 29400: time = 0:00:07.691312 last_best_loss = 17.134441375732422, this_loss = 16.973302841186523\n",
      "Iteration 29500: time = 0:00:07.669276 last_best_loss = 17.134441375732422, this_loss = 17.59740447998047\n",
      "Iteration 29600: time = 0:00:07.701792 last_best_loss = 17.134441375732422, this_loss = 17.335241317749023\n",
      "Iteration 29700: time = 0:00:07.648900 last_best_loss = 17.134441375732422, this_loss = 17.254871368408203\n",
      "Iteration 29800: time = 0:00:07.690779 last_best_loss = 17.134441375732422, this_loss = 16.80583953857422\n",
      "Iteration 29900: time = 0:00:07.666496 last_best_loss = 17.134441375732422, this_loss = 17.177906036376953\n",
      "Iteration 30000: time = 0:00:07.680475 last_best_loss = 17.134441375732422, this_loss = 17.6214599609375\n",
      "Iteration 30100: time = 0:00:07.923178 last_best_loss = 17.134441375732422, this_loss = 17.31648063659668\n",
      "Iteration 30200: time = 0:00:07.663462 last_best_loss = 17.134441375732422, this_loss = 17.400243759155273\n",
      "Iteration 30300: time = 0:00:07.600523 last_best_loss = 17.134441375732422, this_loss = 17.573041915893555\n",
      "Iteration 30400: time = 0:00:07.669383 last_best_loss = 17.134441375732422, this_loss = 17.778825759887695\n",
      "Iteration 30500: time = 0:00:07.742415 last_best_loss = 17.134441375732422, this_loss = 16.73111915588379\n",
      "Iteration 30600: time = 0:00:07.673930 last_best_loss = 17.134441375732422, this_loss = 17.499893188476562\n",
      "Iteration 30700: time = 0:00:07.765725 last_best_loss = 17.134441375732422, this_loss = 17.589885711669922\n",
      "Iteration 30800: time = 0:00:07.701603 last_best_loss = 17.134441375732422, this_loss = 17.430688858032227\n",
      "Iteration 30900: time = 0:00:07.734142 last_best_loss = 17.134441375732422, this_loss = 16.68651580810547\n",
      "Iteration 31000: time = 0:00:07.861745 last_best_loss = 17.134441375732422, this_loss = 17.10147476196289\n",
      "Iteration 31100: time = 0:00:07.694681 last_best_loss = 17.134441375732422, this_loss = 17.754674911499023\n",
      "Iteration 31200: time = 0:00:07.713834 last_best_loss = 17.134441375732422, this_loss = 17.09546661376953\n",
      "Iteration 31300: time = 0:00:07.718175 last_best_loss = 17.134441375732422, this_loss = 17.659427642822266\n",
      "Iteration 31400: time = 0:00:07.678112 last_best_loss = 17.134441375732422, this_loss = 16.96571922302246\n",
      "Iteration 31500: time = 0:00:07.736941 last_best_loss = 17.134441375732422, this_loss = 17.863679885864258\n",
      "Iteration 31600: time = 0:00:07.744652 last_best_loss = 17.134441375732422, this_loss = 16.75238800048828\n",
      "Iteration 31700: time = 0:00:07.743758 last_best_loss = 17.134441375732422, this_loss = 17.848316192626953\n",
      "Iteration 31800: time = 0:00:08.066496 last_best_loss = 17.134441375732422, this_loss = 17.009132385253906\n",
      "Iteration 31900: time = 0:00:07.709660 last_best_loss = 17.134441375732422, this_loss = 17.995227813720703\n",
      "Iteration 32000: time = 0:00:07.914618 last_best_loss = 17.134441375732422, this_loss = 17.037229537963867\n",
      "Iteration 32100: time = 0:00:07.805137 last_best_loss = 17.134441375732422, this_loss = 17.222000122070312\n",
      "Iteration 32200: time = 0:00:07.637630 last_best_loss = 17.134441375732422, this_loss = 17.148906707763672\n",
      "Iteration 32300: time = 0:00:07.671150 last_best_loss = 17.134441375732422, this_loss = 17.4925479888916\n",
      "Iteration 32400: time = 0:00:07.960636 last_best_loss = 17.134441375732422, this_loss = 17.069644927978516\n",
      "Iteration 32500: time = 0:00:08.220074 last_best_loss = 17.134441375732422, this_loss = 16.76638412475586\n",
      "Iteration 32600: time = 0:00:07.637447 last_best_loss = 17.134441375732422, this_loss = 17.76839828491211\n",
      "Iteration 32700: time = 0:00:08.288714 last_best_loss = 17.134441375732422, this_loss = 17.762353897094727\n",
      "Iteration 32800: time = 0:00:07.762762 last_best_loss = 17.134441375732422, this_loss = 17.44843101501465\n",
      "Iteration 32900: time = 0:00:07.896848 last_best_loss = 17.134441375732422, this_loss = 17.199417114257812\n",
      "Iteration 33000: time = 0:00:08.027435 last_best_loss = 17.134441375732422, this_loss = 17.413040161132812\n",
      "Iteration 33100: time = 0:00:07.963522 last_best_loss = 17.134441375732422, this_loss = 17.95610809326172\n",
      "Iteration 33200: time = 0:00:08.104027 last_best_loss = 17.134441375732422, this_loss = 17.618648529052734\n",
      "Iteration 33300: time = 0:00:07.689975 last_best_loss = 17.134441375732422, this_loss = 17.466323852539062\n",
      "Iteration 33400: time = 0:00:07.928011 last_best_loss = 17.134441375732422, this_loss = 17.462642669677734\n",
      "Iteration 33500: time = 0:00:07.708591 last_best_loss = 17.134441375732422, this_loss = 16.953330993652344\n",
      "Iteration 33600: time = 0:00:08.497215 last_best_loss = 17.134441375732422, this_loss = 18.363134384155273\n",
      "Iteration 33700: time = 0:00:07.725953 last_best_loss = 17.134441375732422, this_loss = 17.009815216064453\n",
      "Iteration 33800: time = 0:00:08.413870 last_best_loss = 17.134441375732422, this_loss = 17.401058197021484\n",
      "Iteration 33900: time = 0:00:08.594624 last_best_loss = 17.134441375732422, this_loss = 17.46224021911621\n",
      "Iteration 34000: time = 0:00:08.425138 last_best_loss = 17.134441375732422, this_loss = 17.719165802001953\n",
      "Iteration 34100: time = 0:00:07.694256 last_best_loss = 17.134441375732422, this_loss = 16.903345108032227\n",
      "Iteration 34200: time = 0:00:08.760730 last_best_loss = 17.134441375732422, this_loss = 17.116809844970703\n",
      "Iteration 34300: time = 0:00:08.887471 last_best_loss = 17.134441375732422, this_loss = 17.205474853515625\n",
      "Iteration 34400: time = 0:00:08.833247 last_best_loss = 17.134441375732422, this_loss = 17.258623123168945\n",
      "Iteration 34500: time = 0:00:08.536284 last_best_loss = 17.134441375732422, this_loss = 17.754379272460938\n",
      "Iteration 34600: time = 0:00:08.156403 last_best_loss = 17.134441375732422, this_loss = 17.31527328491211\n",
      "Iteration 34700: time = 0:00:07.699708 last_best_loss = 17.134441375732422, this_loss = 17.20736312866211\n",
      "Iteration 34800: time = 0:00:08.519591 last_best_loss = 17.134441375732422, this_loss = 16.977378845214844\n",
      "Iteration 34900: time = 0:00:08.670243 last_best_loss = 17.134441375732422, this_loss = 16.89432144165039\n",
      "Iteration 35000: time = 0:00:08.572326 last_best_loss = 17.134441375732422, this_loss = 17.58310317993164\n",
      "Iteration 35100: time = 0:00:08.597315 last_best_loss = 17.134441375732422, this_loss = 17.001266479492188\n",
      "Iteration 35200: time = 0:00:09.535625 last_best_loss = 17.134441375732422, this_loss = 17.278446197509766\n",
      "Iteration 35300: time = 0:00:08.560180 last_best_loss = 17.134441375732422, this_loss = 16.802200317382812\n",
      "Iteration 35400: time = 0:00:08.354562 last_best_loss = 17.134441375732422, this_loss = 16.70600128173828\n",
      "Iteration 35500: time = 0:00:08.841326 last_best_loss = 17.134441375732422, this_loss = 17.26811981201172\n",
      "Iteration 35600: time = 0:00:08.560213 last_best_loss = 17.134441375732422, this_loss = 17.930519104003906\n",
      "Iteration 35700: time = 0:00:07.778310 last_best_loss = 17.134441375732422, this_loss = 17.326454162597656\n",
      "Iteration 35800: time = 0:00:07.659028 last_best_loss = 17.134441375732422, this_loss = 16.97158432006836\n",
      "Iteration 35900: time = 0:00:07.750310 last_best_loss = 17.134441375732422, this_loss = 17.151168823242188\n",
      "Iteration 36000: time = 0:00:07.714589 last_best_loss = 17.134441375732422, this_loss = 16.766942977905273\n",
      "Iteration 36100: time = 0:00:07.765005 last_best_loss = 17.134441375732422, this_loss = 16.48177719116211\n",
      "Iteration 36200: time = 0:00:07.844573 last_best_loss = 17.134441375732422, this_loss = 17.526264190673828\n",
      "Iteration 36300: time = 0:00:07.848198 last_best_loss = 17.134441375732422, this_loss = 17.98896026611328\n",
      "Iteration 36400: time = 0:00:07.738965 last_best_loss = 17.134441375732422, this_loss = 17.129661560058594\n",
      "Iteration 36500: time = 0:00:07.953861 last_best_loss = 17.134441375732422, this_loss = 17.774864196777344\n",
      "Iteration 36600: time = 0:00:07.979966 last_best_loss = 17.134441375732422, this_loss = 17.41944694519043\n",
      "Iteration 36700: time = 0:00:07.725990 last_best_loss = 17.134441375732422, this_loss = 16.734703063964844\n",
      "Iteration 36800: time = 0:00:07.741977 last_best_loss = 17.134441375732422, this_loss = 17.454565048217773\n",
      "Iteration 36900: time = 0:00:07.749900 last_best_loss = 17.134441375732422, this_loss = 17.598485946655273\n",
      "Iteration 37000: time = 0:00:07.733990 last_best_loss = 17.134441375732422, this_loss = 17.556270599365234\n",
      "Iteration 37100: time = 0:00:07.725888 last_best_loss = 17.134441375732422, this_loss = 16.612632751464844\n",
      "Iteration 37200: time = 0:00:07.676710 last_best_loss = 17.134441375732422, this_loss = 16.96883773803711\n",
      "Iteration 37300: time = 0:00:07.718376 last_best_loss = 17.134441375732422, this_loss = 16.689136505126953\n",
      "Iteration 37400: time = 0:00:07.667867 last_best_loss = 17.134441375732422, this_loss = 17.222232818603516\n",
      "Iteration 37500: time = 0:00:07.660799 last_best_loss = 17.134441375732422, this_loss = 16.694488525390625\n",
      "Iteration 37600: time = 0:00:07.765988 last_best_loss = 17.134441375732422, this_loss = 17.9143123626709\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-c8a61a8d4979>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;31m# a million iterations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m     \u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# remember to change cuda device\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprev_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_pred\u001b[0m  \u001b[0;34m=\u001b[0m \u001b[0mmod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/AllrecipeAnalytics/skip_thoughts/data_loader.py\u001b[0m in \u001b[0;36mfetch_batch\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfirst_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfirst_index\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m             \u001b[0msent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msentences\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0mind\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_sentence_to_indices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m             \u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0mlengths\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAXLEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/workspace/AllrecipeAnalytics/skip_thoughts/data_loader.py\u001b[0m in \u001b[0;36mconvert_sentence_to_indices\u001b[0;34m(self, sentence)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mUSE_CUDA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCUDA_DEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "filename = '../data/skip_thoughts_corpus_71.csv'\n",
    "lr=3e-4\n",
    "start = 0\n",
    "end = 1000000\n",
    "batch_size=32\n",
    "\n",
    "#################################\n",
    "\n",
    "d = DataLoader(filename)\n",
    "mod = UniSkip()\n",
    "if USE_CUDA:\n",
    "    mod.cuda(CUDA_DEVICE)\n",
    "\n",
    "optimizer = torch.optim.Adam(params=mod.parameters(), lr=lr)\n",
    "last_best_loss = None\n",
    "loss_trail = []\n",
    "current_time = datetime.utcnow()\n",
    "\n",
    "# a million iterations\n",
    "for i in range(start, end):\n",
    "    sentences, lengths = d.fetch_batch(batch_size) # remember to change cuda device\n",
    "\n",
    "    loss, prev, nex, prev_pred, next_pred  = mod(sentences, lengths)\n",
    "    if i % 100 == 0:\n",
    "        debug(i, loss, prev, nex, prev_pred, next_pred, saveto = filename[:-4]+'/')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
